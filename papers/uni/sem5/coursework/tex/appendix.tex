\titleformat{\section}[block]
  {\large\bfseries\centering}
  {\thesection\ }{}{}
\chapter*{ПРИЛОЖЕНИЕ А}
\addcontentsline{toc}{chapter}{ПРИЛОЖЕНИЕ А}
\section*{\centering Код программы. Подготовка набора данных}
\begin{footnotesize}
\begin{lstlisting}
import numpy as np
import librosa
from os import walk, path

import warnings
warnings.filterwarnings('ignore')

class DataParser:
    def __init__(self, root, duration=None, pickle=None):
        self.pickle = pickle
        self.duration = duration
        self.root = root
        genres = [x[0] for x in walk(self.root)][1:]
        self.label_mapping = {genre: index for (index, genre) in enumerate(genres)}

    def to_label(self, string):
        return self.label_mapping[string]

    def to_string(self, label):
        label_mapping = {value: key for (key,value) in self.label_mapping}
        return label_mapping[label]

    def extract_features(self, file_path):
        raw, rate = librosa.load(file_path, duration=30)
        stft = np.abs(librosa.stft(raw))
        mfcc = np.mean(librosa.feature.mfcc(y=raw,sr=rate,n_mfcc=40).T, axis=0)
        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=rate).T, axis=0)
        mel = np.mean(librosa.feature.melspectrogram(y=raw, sr=rate).T, axis=0)
        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=rate).T, axis=0)
        tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(raw), sr=rate).T, axis=0)
        return [mfcc, chroma, mel, contrast, tonnetz]

    def from_files(self):
        labels = []
        samples = []

        for glob in list(walk(self.root))[1:]:
            subdir, songs = glob[0], glob[2]
            print(f"{subdir}")
            for song in songs:
                print(song)
                features = self.extract_features(path.join(subdir, song))
                samples.append(np.hstack(features))
                labels.append(self.to_label(subdir))
        return np.array(samples), np.array(labels)

    def from_pickle(self):
        if self.pickle:
            return np.load(self.pickle, allow_pickle=True)

def main():
    root = input()
    parser = DataParser(root=root)
    samples, labels = parser.from_files()
    np.save(f"{root}_samples.npy", samples, allow_pickle=True)
    np.save(f"{root}_labels.npy", labels, allow_pickle=True)

if __name__ == "__main__":
    main()

\end{lstlisting}
\end{footnotesize}

\chapter*{ПРИЛОЖЕНИЕ Б}
\addcontentsline{toc}{chapter}{ПРИЛОЖЕНИЕ Б}
\section*{\centering Код программы. Обучение нейросетей}
\begin{footnotesize}
\begin{lstlisting}
import numpy as np
from sklearn.cluster import KMeans
from data import DataParser
import matplotlib.pyplot as plt
import pandas as pd
from itertools import permutations 
import tensorflow as tf

import warnings
warnings.filterwarnings('ignore')


def main():
    labels = np.load("mus_labels.npy")
    samples = np.load(f"mus_samples.npy", allow_pickle=True)
    test_labels = np.load("test_labels.npy")
    test_samples = np.load(f"test_samples.npy", allow_pickle=True)

    kmeans = KMeans(n_clusters=4)
    kmeans.fit(samples)
    predicted_labels = kmeans.predict(test_samples)

    perms = permutations([0, 1, 2, 3]) 

    rate = 0
    mapping = {}
    for perm in perms:
        new_mapping = {index: value for (index, value) in enumerate(perm)}
        correct = sum([1 if test_label == new_mapping[label] else 0 for (test_label, label) in zip(test_labels, predicted_labels)])
        new_rate = correct / len(test_labels)
        if new_rate > rate:
            rate = new_rate
            mapping = new_mapping

    print(rate)
    print(list(test_labels))
    print([mapping[label] for label in predicted_labels])


    model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape=(193,)), tf.keras.layers.Dense(128, activation='relu'), tf.keras.layers.Dense(4) ])
    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])
    model.fit(samples, labels, epochs=20)
    test_loss, test_acc = model.evaluate(test_samples,  test_labels)
    print('\nTest accuracy:', test_acc)

    predict = model.predict(test_samples)

    embedding = MDS(n_components=2, metric=True, n_init=10, eps=0.001)
    reducted = embedding.fit_transform(predict)
    print(reducted)

    plt.scatter(reducted[:, 0], reducted[:, 1], c=test_labels)
    plt.show()


if __name__ == "__main__":
    main()
\end{lstlisting}
\end{footnotesize}